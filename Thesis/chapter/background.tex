\newcommand{\privkey}{\mathcal{K}_{\mathsf{priv}}}
\newcommand{\pubkey}{\mathcal{K}_{\mathsf{pub}}}
\newcommand{\enc}[1]{\mathsf{ENC}_{\privkey}(#1)}
\newcommand{\encpub}[1]{\mathsf{ENC}_{\pubkey}(#1)}
\newcommand{\dec}[1]{\mathsf{DEC}_{\privkey}(#1)}

\chapter{Background}
\section{Overview}
In this chapter, the field of cryptography and cryptanalysis will be introduced, with an emphasis on digital signatures and cryptanalysis.  
The chapter will also introduce some necessary facts and notions related to algebra, linear algebra and lattices, and probability theory and statistics.
Lastly, we introduce the notion of Gradient Descent, which will be a central tool in this thesis.

\section{Cryptography}
Cryptography is the study of tools and techniques that enable secure and, in part, reliable communication. For centuries, this entailed creative systems of codes and techniques used predominantly by military and governments,
and the creation and breaking of such systems were considered an art. % based on creativity and \todo{Find a source that backs the linguistics claim} linguistics, as cryptography then were used mostly on natural language. 
From the 1970s and onwards, however, mathematics increasingly becomes the backbone of cryptography, as mathematical theory provides provable security (and insecurity) of cryptographic systems. 
In the recent 50 years or so, cryptography has become an enabler of secure communication, verification, and integrity of information, all of which are integral aspects in our digital world. \cite{KL20}

Symmetric key cryptography enables secure communication between two or more parties and utilizes a shared secret key, denoted $\privkey$. 
The system defines two functions, $\enc{\mathcal{M}}$ and $\dec{\mathcal{C}}$ that encrypt and decrypt a message, respectively. These functions depend on the input message and the secret key. 
% For a proper system these functions are inverse of each other, i.e. $\dec{\enc{\mathcal{M}}} = \mathcal{M}$. 
Anyone without knowledge of $\privkey$ should be unable to
extract any meaningful information about either $\privkey$ or $\mathcal{M}$ based only on observing $\mathcal{C}$.

Asymmetric key cryptography on the other hand utilizes two related, but distinct keys; one private and one public, denoted $\privkey$ and $\pubkey$.
Anyone with access to $\pubkey$ can encrypt a message $\mathcal{M}$ as $\mathcal{C} = \encpub{\mathcal{M}}$, rendering it unreadable. Only the holder of $\privkey$ is able to decrypt the message
as $\mathcal{M} = \dec{\mathcal{C}}$. A crucial security property of such a system is that one should not be able to somehow deduce what $\privkey$ is if one has access only to $\pubkey$.

The security of asymmetric cryptography is usually based on hard mathematical problems for which an effective algorithm to solve is either unknown to exist, or proven \textit{not} to exist. 
For example, to decrypt a message encrypted in the RSA scheme \cite{RSA78} without possession of the secret key, one would need to find two large prime numbers $p$ and $q$ such that 
$p \cdot q = n$, where $n$ is the RSA modulus used in its encryption algorithm. For specific and large enough values of $n$, this is considered a hard problem. \cite{ENCYCLOPEDIA}
Other asymmetric cryptography schemes may utilize different hard problems as a basis for their security, such as the "Discrete Logarithm Problem", "Closest Vector Problem", and "Learning With Errors", to name a few.

One of the main applications of asymmetric cryptography are digital signatures. A digital signature $\mathcal{S}$ computed from a message $\mathcal{M}$ enable a receiver of the 
message-signature pair $(\mathcal{M}, \mathcal{S})$ to mathematically verify that the sender is in possession of the private key $\privkey$ that relates to the receivers public key $\pubkey$.
In addition, a signature $\mathcal{S}$ guarantees that the original message $\mathcal{M}$ is intact and has not changed since the computation of $\mathcal{S}$.
Section 2.4 will go in further detail about the building blocks for digital signature schemes, and what constitutes a secure or insecure scheme.

% An important application for asymmetric cryptography includes:
% \begin{itemize}
%     \item \textbf{Secret key distribution:} the issue of exchanging secret keys for symmetric cryptography has long been a challenge. To overcome this challenge, one of two members in a party can encrypt a secret (symmetric) key using a public key,
%         and the other party member can decrypt the (symmetric) key using his or her own (asymmetric) private key. Now that both members of the party are in possession of the same symmetric private key, they can resume communication using symmetric cryptography, which
%         is generally much more efficient in encrypting and decrypting large messages.
%     \item \textbf{Verification of sender:} analogous to digital signatures (which will be explained more thoroughly in section 2.4), by computing an encrypted version of a message using an asymmetric private key, anyone with knowledge of the public key
%         is able to decrypt the message. Importantly, the receiver is now able to verify that the intended message was encrypted with the private key related to the publicly available one. If the sender encrypted the message 
%         with another private key, the recipient would quickly realize that the sender is not in possession of the "correct" secret key. This is a gross oversimplification of how
%         such systems work, but as we will see later, this property of asymmetric cryptography, alongside other cryptographic primitives such as hash functions, create a strong foundation for digital signatures.
%     \todo{Rewrite this entire point}
% \end{itemize}

\section{Cryptanalysis}
Cryptanalysis is the study of analyzing and breaking cryptographic systems, and it plays an important role in strengthening the cryptography we use today.
By analyzing a system and exposing potential flaws and weaknesses, the designers of such as system can make suitable changes to it (or in extreme cases, discard it entirely) to further 
increase its security against adversaries with malicious intent, or altogether avoid the release of an insecure piece of technology.

The notion of a cryptanalytic \textit{attack} refers to a methodical attempt of retrieving secret information from an instance of a cryptographic scheme.
This can be either attempting to recover parts of, or the entire, secret key, deduce some information about an encrypted message, or somehow produce 
some information (e.g. creating a valid digital signature) as if one possesses the secret key. Generally, if any degree of the mentioned points is possible for a scheme, 
the scheme should be considered insecure or broken, and the attack can be considered successful.

An important consideration when designing and analyzing the security of an asymmetric crypto-system, is that a scheme is generally only as strong as its weakest part. \todo{Maybe find some direct source for this?}
In practice, even if a scheme is based on a provably hard problem, there may be other components of the scheme that renders it unsafe.
As an example, the security of the NTRU-sign digital signature scheme is based upon the CVP. 
This means that without possession of the secret key, forging a signature would require one to solve an instance of CVP, which is generally considered hard. 
However, as we will see in section 3, each generated signature leaks some information about the secret key, which ultimately enables signature forgeries, regardless of whether one can 
solve the CVP or not. 

\section{Digital Signatures}
\subsection{Hash-and-Sign}
\subsection{Security of Digital Signatures}
\subsection{GGH}
\subsection{NTRU}

\section{Algebra}
\subsection{Polynomials}
\subsection{Polynomial rings}
\subsection{Number fields}

\section{Linear Algebra and Lattices}
Denote by $\vec{v}$ an $n \times 1$ column vector on the form 
\[ \vec{v} = \begin{bmatrix} v_0 \\ v_1 \\ ... \\ v_{n-1} \end{bmatrix}\] and by $\mat{B}$ an $n \times m$ matrix on the form 
\[
    \mat{B} = 
    \begin{bmatrix}
        b_{0,0} & b_{0,1} & \cdots & b_{0, n-1} \\ 
        b_{1,0} & b_{1,1} & \cdots & b_{1, n-1} \\ 
        \cdots & \cdots & \cdots & \cdots\\
        b_{m-1,0} & b_{m-1,1} & \cdots & b_{m-1, n-1} \\ 
    \end{bmatrix}
\]

Generally, entries $v_i$ and $b_{i, j}$ are integers unless stated otherwise.
Some places the thesis will use row notation instead of column notation for the vectors, so that $\vec{v}$ is a $1 \times n$ row vector on the form
\[\vec{c} = [v_0, v_1, ..., v_{n-1}]\] In these cases this will be pointed out.

We denote by $\langle \cdot, \cdot \rangle$ the dot-product of two vectors of equal dimensions as \\
$\langle \vec{x}, \vec{y} \rangle = \vec{x}^t \vec{y} = \mathlarger{\sum_{i=0}^{n-1} x_i y_i}$
\section{Probability Theory}
\subsection{Central Limit Theorem and sample size estimation}
A result in statistics that will be useful in this thesis is the Central Limit Theorem (CLT).
The CLT states that when observing samples $\{X_1, X_2, ..., X_n\}$ from a distribution, the sample mean, denoted $\hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} X_n$ follows a normal distribution 
when number of samples n grow sufficiently large, even though the original distribution $X$ follows is not normal.

\section{Gradient Search}
\subsection{Overview}
Used in this section: \cite{R17}
Gradient descent is a widely used method in optimization and learning problems.

The general method works by measuring the gradient of the target function $\nabla f (\theta) $ w.r.t. to its parameters $\theta$ to get the direction 
in which $\theta$ $f(\theta)$ changes the most. 
One then takes a "step" based on this direction (for a descent, one moves against the gradient, for an ascent, with the gradient), 
influenced by the hyperparameter $\delta$, which determines the magnitude of the step.

Before going more in depth of the methods, we quickly define the gradient of a function.
\subsection{Gradients}
Let $\theta = [\theta_1, \theta_2, \cdots, \theta_n]$
The gradient of a multivariate function $f(\theta)$ is defined as the vector of partial derivatives evaluated at $\theta$

\[ \nabla f(\theta) = 
\begin{bmatrix}
\frac{\partial f}{\partial \theta_1}(\theta) \\
\frac{\partial f}{\partial \theta_2}(\theta) \\
\cdots \\
\frac{\partial f}{\partial \theta_n}(\theta) \\
\end{bmatrix}
\]

\subsection{Gradient descent and optimization}
In Algorithm \ref{VanillaGradientDescent} the so-called "vanilla" gradient descent is described.
\begin{algorithm}[H]
    \caption{Vanilla gradient descent} \label{VanillaGradientDescent}
\begin{algorithmic}[1]
    \Require{differentiable target function $f$}
    \State initialize $\theta_0$ as a starting point
    \While{$\theta_t$ is not optimal}
    \State $\theta_t \gets \theta_{t-1} - \delta \cdot \nabla f_{\theta} (\theta_{t-1})$
    \EndWhile
\end{algorithmic}
\end{algorithm}

Note that for vanilla gradient descent as described in Algorithm \ref{VanillaGradientDescent}, to compute the gradient one needs the entire dataset for each iteration,
which sometimes can be too large to fit in memory or be computationally efficient.

Due to the popularity of gradient descent in especially machine learning, many optimization techniques exist that improve upon the vanilla method.
In this thesis, however, we stick to the vanilla version.
